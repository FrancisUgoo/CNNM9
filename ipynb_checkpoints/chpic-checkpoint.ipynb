{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "564dd800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "\n",
    "\n",
    "# import required libraries\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "36c8799b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/ffhq_0.png is saved\n",
      "2\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/ffhq_121.png is saved\n",
      "3\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/ffhq_14.png is saved\n",
      "4\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/ffhq_18.png is saved\n",
      "5\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/ffhq_23.png is saved\n",
      "6\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/ffhq_3.png is saved\n",
      "7\n",
      "Number of detected faces: 0\n",
      "Number of detected faces: 0\n",
      "Number of detected faces: 0\n",
      "Number of detected faces: 0\n",
      "8\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/image0000068.jpg is saved\n",
      "9\n",
      "Number of detected faces: 0\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/image0000213.jpg is saved\n",
      "10\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/image0000965.jpg is saved\n",
      "11\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/image0001434.jpg is saved\n",
      "12\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/image0001934.jpg is saved\n",
      "13\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/image0001974.jpg is saved\n",
      "14\n",
      "Number of detected faces: 2\n",
      "C:/Users/research/Desktop/thesis/test/aaza/image0002061.jpg is saved\n",
      "C:/Users/research/Desktop/thesis/test/aaza/image0002061.jpg is saved\n",
      "15\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/image0002832.jpg is saved\n",
      "16\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/image0002849.jpg is saved\n",
      "17\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/image0003201.jpg is saved\n",
      "18\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/image0009996.jpg is saved\n",
      "19\n",
      "Number of detected faces: 0\n",
      "Number of detected faces: 0\n",
      "Number of detected faces: 0\n",
      "Number of detected faces: 0\n",
      "20\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/Screenshot_20221101-073819_Opera Mini.jpg is saved\n",
      "21\n",
      "Number of detected faces: 0\n",
      "Number of detected faces: 0\n",
      "Number of detected faces: 0\n",
      "Number of detected faces: 0\n",
      "22\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/woman-suffering-stress-headache-grimacing-260nw-192268697.jpg is saved\n",
      "23\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/young-african-american-man-holding-260nw-1820939108.jpg is saved\n",
      "24\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/young-fit-sporty-woman-painful-260nw-1019069947.jpg is saved\n",
      "25\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/young-funny-handsome-man-beard-260nw-1184217358.jpg is saved\n",
      "26\n",
      "Number of detected faces: 1\n",
      "C:/Users/research/Desktop/thesis/test/aaza/young-girl-keeps-hand-on-260nw-571576168.jpg is saved\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "dirx = \"C:/Users/research/Desktop/thesis/test/aaz\"\n",
    "ndir = \"C:/Users/research/Desktop/thesis/test/aaza\"\n",
    "for files in os.listdir(dirx):\n",
    "    count = count + 1\n",
    "    print(count)\n",
    "    ndirx = dirx + '/' + files\n",
    "    nmane = ndir + '/' + files\n",
    "    #print(ndirx)\n",
    "    # read the input image\n",
    "    img = cv2.imread(ndirx)\n",
    "    # convert to grayscale of each frames\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # read the haarcascade to detect the faces in an image\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "    # detects faces in the input image\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    print('Number of detected faces:', len(faces))\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        # read the haarcascade to detect the faces in an image\n",
    "        face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt2.xml')\n",
    "        # detects faces in the input image\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 2)\n",
    "        print('Number of detected faces:', len(faces))\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        # read the haarcascade to detect the faces in an image\n",
    "        face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "        # detects faces in the input image\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 4)\n",
    "        print('Number of detected faces:', len(faces))\n",
    "        \n",
    "    if len(faces) == 0:\n",
    "        # read the haarcascade to detect the faces in an image\n",
    "        face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_profileface.xml')\n",
    "        # detects faces in the input image\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 2)\n",
    "        print('Number of detected faces:', len(faces))\n",
    "    if len(faces) > 0:\n",
    "        for i, (x, y, w, h) in enumerate(faces):\n",
    "            # To draw a rectangle in a face\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 255), 2)\n",
    "            face = img[y:y + h, x:x + w]\n",
    "            #cv2.imshow(\"Cropped Face\", face)\n",
    "            face = cv2.resize(face, (224, 224))\n",
    "            cv2.imwrite(f'{nmane}', face)\n",
    "            print(f\"{nmane} is saved\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da14f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#testing image read the input image\n",
    "img = cv2.imread(\"test/young-girl-keeps-hand-on-260nw-571576168.jpg\")\n",
    "#img = cv2.imread(\"JuVIA.png\")\n",
    "plt.imshow(img)\n",
    "\n",
    "# convert to grayscale of each frames\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# read the haarcascade to detect the faces in an image\n",
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "# detects faces in the input image\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "print('Number of detected faces:', len(faces))\n",
    "\n",
    "if len(faces) == 0:\n",
    "    # read the haarcascade to detect the faces in an image\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt2.xml')\n",
    "    # detects faces in the input image\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 2)\n",
    "    print('Number of detected faces:', len(faces))\n",
    "    \n",
    "if len(faces) == 0:\n",
    "    # read the haarcascade to detect the faces in an image\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "    # detects faces in the input image\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 4)\n",
    "    print('Number of detected faces:', len(faces))\n",
    "    \n",
    "if len(faces) == 0:\n",
    "    # read the haarcascade to detect the faces in an image\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_profileface.xml')\n",
    "    # detects faces in the input image\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 2)\n",
    "    print('Number of detected faces:', len(faces))\n",
    "    \n",
    "    \n",
    "if len(faces) > 0:\n",
    "    for i, (x, y, w, h) in enumerate(faces):\n",
    "        # To draw a rectangle in a face\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 255), 2)\n",
    "        face = img[y:y + h, x:x + w]\n",
    "        #cv2.imshow(\"Cropped Face\", face)\n",
    "        cv2.imwrite(f'face{i}.jpg', face)\n",
    "        print(f\"face{i}.jpg is saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf55784",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c39a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "dirx = \"C:/Users/research/Desktop/z8\"\n",
    "ndir = \"C:/Users/research/Desktop/8\"\n",
    "for files in os.listdir(dirx):\n",
    "    count = count + 1\n",
    "    print(count)\n",
    "    ndirx = dirx + '/' + files\n",
    "    nmane = ndir + '/' + files\n",
    "    #print(ndirx)\n",
    "    # read the input image\n",
    "    img = cv2.imread(ndirx)\n",
    "    # convert to grayscale of each frames\n",
    "    #gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # read the haarcascade to detect the faces in an image\n",
    "    #face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "    # detects faces in the input image\n",
    "    #faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    #print('Number of detected faces:', len(faces))\n",
    "    if 1 > 0:\n",
    "        face = cv2.resize(img, (224, 224))\n",
    "        \n",
    "        #cv2.imshow(\"Cropped Face\", face)\n",
    "        ###nmane = nmane.replace(\"612x612\", \"612x612a\")\n",
    "        cv2.imwrite(f'{nmane}', face)\n",
    "        print(f\"{nmane} is saved\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca7e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3304d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "# display the image with detected faces\n",
    "#cv2.imshow(\"image\", img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a65c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "dirx = \"aa\"\n",
    "ndir = \"zppimgs\"\n",
    "for files in os.listdir(dirx):\n",
    "    count = count + 1\n",
    "    print(count)\n",
    "    ndirx = dirx + '/' + files\n",
    "    nmane = ndir + '/' + files\n",
    "    #print(ndirx)\n",
    "    # read the input image\n",
    "    img = cv2.imread(ndirx)\n",
    "    # convert to grayscale of each frames\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # read the haarcascade to detect the faces in an image\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "    # detects faces in the input image\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    print('Number of detected faces:', len(faces))\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        # read the haarcascade to detect the faces in an image\n",
    "        face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt2.xml')\n",
    "        # detects faces in the input image\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 2)\n",
    "        print('Number of detected faces:', len(faces))\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        # read the haarcascade to detect the faces in an image\n",
    "        face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "        # detects faces in the input image\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 4)\n",
    "        print('Number of detected faces:', len(faces))\n",
    "        \n",
    "    if len(faces) == 0:\n",
    "        # read the haarcascade to detect the faces in an image\n",
    "        face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_profileface.xml')\n",
    "        # detects faces in the input image\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 2)\n",
    "        print('Number of detected faces:', len(faces))\n",
    "    if len(faces) > 0:\n",
    "        rrcount = 1\n",
    "        for i, (x, y, w, h) in enumerate(faces):\n",
    "            # To draw a rectangle in a face\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 255), 2)\n",
    "            face = img[y:y + h, x:x + w]\n",
    "            #cv2.imshow(\"Cropped Face\", face)\n",
    "            new_jpg = str(rrcount) + \".jpg\"\n",
    "            new_nmane = nmane.replace(\".jpg\", new_jpg)\n",
    "            cv2.imwrite(f'{new_nmane}', face)\n",
    "            rrcount = rrcount + 1\n",
    "            print(f\"{new_nmane} is saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb3063f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18d40b54220>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img1 = cv2.imread(\"C:/Users/research/Desktop/fer2013/test/surprise/PrivateTest_1338609.jpg\")\n",
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34efcf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_img = cv2.resize(img1, (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47251f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_img = np.expand_dims(final_img,axis =0) #adding fourth dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dba7fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_img = final_img/255.0 #normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fac834a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cb48af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_modelp = load_model(\"my_apain_model_91ep.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "979a8a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions = new_modelp.predict(final_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c4aed86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.3320218e-06, 3.0750861e-02, 1.5119085e-09, 6.9305330e-09,\n",
       "       9.6924579e-01, 4.1111601e-08], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66a73f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afb82044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.7501421e-01 2.1020124e-02 1.6698646e-04 3.4313460e-04 3.3736068e-03\n",
      "  8.1952967e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "217a5085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "from skimage import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "# import required libraries\n",
    "import cv2\n",
    "import os\n",
    "from skimage import img_as_ubyte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85d9b3de",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:/Users/research/Desktop/adell'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m dirx \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/research/Desktop/adell\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m ndir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/research/Desktop/adell\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m files \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirx\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      5\u001b[0m     count \u001b[38;5;241m=\u001b[39m count \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(count)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:/Users/research/Desktop/adell'"
     ]
    }
   ],
   "source": [
    "\n",
    "count = 0\n",
    "dirx = \"C:/Users/research/Desktop/adell\"\n",
    "ndir = \"C:/Users/research/Desktop/adell\"\n",
    "for files in os.listdir(dirx):\n",
    "    count = count + 1\n",
    "    print(count)\n",
    "    ndirx = dirx + '/' + files\n",
    "    nmane = ndir + '/' + files\n",
    "    #print(ndirx)\n",
    "    # read the input image\n",
    "    img = io.imread(ndirx)\n",
    "    imgGray = color.rgb2gray(img)\n",
    "    io.imshow(imgGray)\n",
    "    \n",
    "    imgGray = cv2.resize(imgGray, (48, 48))\n",
    "    io.imsave(nmane, img_as_ubyte(imgGray))\n",
    "    \n",
    "    #cv2.imwrite(f'{nmane}', imgGray)\n",
    "    print(f\"{nmane} is saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a028f55a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
